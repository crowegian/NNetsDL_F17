{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy.random import shuffle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot configurations\n",
    "% matplotlib inline\n",
    "\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1, Part 1: Backpropagation through time (BPTT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Consider a simple RNN network shown in the following figure, where __ _wi, wh, b, a, c_ __ are the scalar parameters of the network. The loss function is the **mean squared error (MSE)**. Given input (x0, x1) = (1, 0), ground truth (g1, g2) = (1, 1), h0 = 0, (wi, wh, b, a, c) = (1, 1, 1, 1, 1), compute __ _(dwi, dwh, db, da, dc)_ __, which are the gradients of loss with repect to 5 parameters __ _(wi, wh, b, a, c)_ __.\n",
    "\n",
    "![bptt](./img/bptt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">TODO:</span>\n",
    "\n",
    "Answer the above question. \n",
    "\n",
    "* **[fill in here: Enter your derivations and the computational process]**\n",
    "* You can use LATEX to edit the equations, and Jupyter notebook can recognize basic LATEX syntax. Alternatively, you can edit equations in some other environment and then paste the screenshot of the equations here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1, Part 2: Use tensorflow modules to create XOR network\n",
    "\n",
    "In this part, you need to build and train an XOR network that can learn the XOR function. It is a very simple implementation of RNN and will give you an idea how RNN is built and how to train it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR network\n",
    "\n",
    "XOR network can learn the XOR $\\oplus$ function\n",
    "\n",
    "As shown in the figure below, and for instance, if input $(x0, x1, x2)$=(1,0,0), then output $(y1, y2, y3)$=(1,1,1). That is, $y_n = x_0\\oplus x_1 \\oplus ... \\oplus x_{n-1}$\n",
    "\n",
    "![xor_net](./img/xor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data set\n",
    "This function provides you the way to generate the data which is required for the training process. You should utilize it when building your training function for the LSTM. Please read the source code for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecbm4040.xor.utils import create_dataset\n",
    "# x, y = create_dataset(num_samples = 2, seq_len=8)\n",
    "# print(x)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a network using a Tensorlow LSTMCell\n",
    "This section shows an example how to build a RNN network using an LSTM cell. LSTM cell is an inbuilt class in tensorflow which implements the real behavior of the LSTM neuron. \n",
    "\n",
    "Reference: [TensorFlow LSTM cell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import LSTMCell\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Input shape: (num_samples, seq_length, input_dimension)\n",
    "# Output shape: (num_samples, output_ground_truth), and output_ground_truth is 0/1. \n",
    "input_data = tf.placeholder(tf.float32,shape=[None,None,1])\n",
    "output_data = tf.placeholder(tf.int64,shape=[None,None])\n",
    "\n",
    "# define LSTM cell\n",
    "lstm_units = 64\n",
    "cell = LSTMCell(lstm_units,num_proj=2,state_is_tuple=True)\n",
    "\n",
    "# create LSTM network: you can also choose other modules provided by tensorflow, like static_rnn etc.\n",
    "out,_ = tf.nn.dynamic_rnn(cell,input_data,dtype=tf.float32)\n",
    "pred = tf.argmax(out,axis=2)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=output_data,logits=out))\n",
    "\n",
    "# optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "# accuracy\n",
    "correct_num = tf.equal(output_data,pred)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_num,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "\n",
    "<span style='color:red'>TODO:</span> \n",
    "1. Build your training funciton for RNN; \n",
    "2. Plot the cost during the traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = create_dataset(num_samples = 2, seq_len=8)\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCmZm1uCkYGZmDU4KZmbW4KRgZmYN/wG58jVIOZ9dXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff8bc939e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracyList = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     merge = tf.summary.merge_all()\n",
    "\n",
    "#     writer = tf.summary.FileWriter(\"log/{}\".format(cur_model_name), sess.graph)\n",
    "#     saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # try to restore the pre_trained\n",
    "\n",
    "    for epc in range(epochs):\n",
    "#         print(\"epoch {} \".format(epc + 1))\n",
    "        _, currLoss = sess.run([optimizer, loss], feed_dict={input_data: x, output_data: y})\n",
    "        currAcc = sess.run([accuracy], feed_dict={input_data: x, output_data: y})\n",
    "#         print('loss: {} accuracy : {}%'.format(currLoss,currAcc))\n",
    "        accuracyList.append(currAcc)\n",
    "#         temp = sess.run([pred], feed_dict={input_data: x, output_data: y})\n",
    "plt.plot(accuracyList)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title(\"Accuracy over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # YOUR TRAINING AND PLOTTING CODE HERE\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "# # Input shape: (num_samples, seq_length, input_dimension)\n",
    "# # Output shape: (num_samples, output_ground_truth), and output_ground_truth is 0/1. \n",
    "# input_data = tf.placeholder(tf.float32,shape=[None,None,1])\n",
    "# output_data = tf.placeholder(tf.int64,shape=[None,None])\n",
    "\n",
    "# # define LSTM cell\n",
    "# lstm_units = 64\n",
    "# cell_rnn = tf.contrib.rnn.BasicRNNCell(num_units = lstm_units,num_proj=2,state_is_tuple=True)\n",
    "# # cell_rnn = tf.contrib.rnn.LSTMCell(num_units = lstm_units)\n",
    "# # tf.contrib.rnn.BasicLSTMCell()\n",
    "# # tf.contrib.rnn.RNNCell()\n",
    "\n",
    "# # create LSTM network: you can also choose other modules provided by tensorflow, like static_rnn etc.\n",
    "# out,_ = tf.nn.dynamic_rnn(cell_rnn,input_data,dtype=tf.float32)\n",
    "# pred = tf.argmax(out,axis=2)\n",
    "\n",
    "# # loss function\n",
    "# loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=output_data,logits=out))\n",
    "\n",
    "# # optimization\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "# # accuracy\n",
    "# correct_num = tf.equal(output_data,pred)\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_num,tf.float32))\n",
    "# epoch = 500\n",
    "# batch_size = 1\n",
    "# iters = int(x.shape[0] / batch_size)\n",
    "# print(iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x, y = create_dataset(num_samples = 10, seq_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracyList = []\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "# #     merge = tf.summary.merge_all()\n",
    "\n",
    "# #     writer = tf.summary.FileWriter(\"log/{}\".format(cur_model_name), sess.graph)\n",
    "# #     saver = tf.train.Saver()\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#     # try to restore the pre_trained\n",
    "\n",
    "#     for epc in range(epoch):\n",
    "# #         print(\"epoch {} \".format(epc + 1))\n",
    "#         _, currLoss = sess.run([optimizer, loss], feed_dict={input_data: x, output_data: y})\n",
    "#         currAcc = sess.run([accuracy], feed_dict={input_data: x, output_data: y})\n",
    "# #         print('loss: {} accuracy : {}%'.format(currLoss,currAcc))\n",
    "#         accuracyList.append(currAcc)\n",
    "# #         temp = sess.run([pred], feed_dict={input_data: x, output_data: y})\n",
    "# plt.plot(accuracyList)\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.title(\"Accuracy over epochs\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.get_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 1, Part 3 :  Build your own LSTMCell\n",
    "In this part, you need to build your own LSTM cell to achieve the LSTM functionality. \n",
    "\n",
    "<span style=\"color:red\">TODO:</span> \n",
    "1. Finish class **MyLSTMCell** in ecbm4040/xor/rnn.py;\n",
    "2. Write the training function for your RNN;\n",
    "3. Plot the cost during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-d4826689bf25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# create LSTM network: you can also choose other modules provided by tensorflow, like static_rnn etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NNetsDL_F17/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NNetsDL_F17/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    759\u001b[0m       \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NNetsDL_F17/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\u001b[0m\n\u001b[1;32m   2773\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2774\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2775\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2776\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NNetsDL_F17/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2602\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m       original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2604\u001b[0;31m           pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2605\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NNetsDL_F17/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2552\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m-> 2554\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2556\u001b[0m       \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NNetsDL_F17/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    744\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    745\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;31m# Pack state if using state tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NNetsDL_F17/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NNetsDL_F17/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m    178\u001b[0m       with vs.variable_scope(vs.get_variable_scope(),\n\u001b[1;32m    179\u001b[0m                              custom_getter=self._rnn_get_variable):\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NNetsDL_F17/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;31m# Apply activity regularization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/currentClasses/NNetsDL_F17/assignment3_Nov11/ecbm4040/xor/rnn.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, state)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# print(tf.contrib.framework.get_name_scope())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0mscope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "from ecbm4040.xor.rnn import MyLSTMCell\n",
    "\n",
    "# recreate xor netowrk with your own LSTM cell\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Input shape: (num_samples,seq_length,input_dimension)\n",
    "#Output shape: (num_samples, output_ground_truth), and output_ground_truth is 0/1. \n",
    "input_data = tf.placeholder(tf.float32,shape=[None,None,1])\n",
    "output_data = tf.placeholder(tf.int64,shape=[None,None])\n",
    "\n",
    "# recreate xor netowrk with your own LSTM cell\n",
    "lstm_units = 64\n",
    "# https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/ops/rnn_cell_impl.py\n",
    "# Use above for this stuff\n",
    "cell = MyLSTMCell(lstm_units,num_proj=2)\n",
    "\n",
    "# create LSTM network: you can also choose other modules provided by tensorflow, like static_rnn etc.\n",
    "out,_ = tf.nn.dynamic_rnn(cell,input_data,dtype=tf.float32)\n",
    "pred = tf.argmax(out,axis=2)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=output_data,logits=out))\n",
    "# optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "# accuracy\n",
    "correct = tf.equal(output_data,pred)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR TRAINING AND PLOTTING CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ob2285/anaconda3/envs/NNetsDL_F17/lib/python3.6/site-packages/tensorflow/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print (tf.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
