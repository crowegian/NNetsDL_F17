{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM4040 Assignment 1, Task 4: Questions\n",
    "\n",
    "1) What is the difference between the SVM method and a neural network, assuming that both work with the same number of training samples N?\n",
    "\n",
    "   Your answer: **The SVM doesn't try to predict probabilities, but rather tries to find a line that separates the data into its different classes. Even though both methods can transform the data (the SVM using the kernel trick and the NNet using repeated affine transformations followed by non-linearities) the NNet can still output class probabilities. The most important difference between the two is that the SVM still requires manual curation of features, while the advantage of NNets is that they can do feature extraction by themselves. The big thing about NNets is their representation learning which occures within the hidden layers.**\n",
    "   \n",
    "   \n",
    "\n",
    "\n",
    "2) Why is the ReLU activation function used the most often in neural networks for computer vision?\n",
    "\n",
    "   Your answer: **In general ReLUs are preferred over other activation methods because of the vanishing gradient problem. ReLU does not have the vanishing gradient problem because it does not saturate like Sigmoid activation functions do.**\n",
    "   \n",
    "\n",
    "3) Describe your best model in the implementation of the two-layer neural network. Describe your starting point, how you tuned  the hyperparameters, which stategies you did you use to improve the network, show the results of intermediate and final steps.\n",
    "\n",
    "   Your answer: **[fill in here]**\n",
    "   \n",
    "\n",
    "4) **Cross validation** is a technique used to prove the generalization ability of a model and can help you find a robust set of hyperparameters. Please describe the implementation details of **k-fold cross validation** if you want to use it to find a best set of hyperparameter of the **Linear SVM classification** problem.\n",
    "\n",
    "   Your answer: **In k-fold cv you split your data randomly into k different sections. You then train on k-1 folds of the data, and test on the left out fold. You repeat this using all folds as a test set once, and then average your performance (accuracy for example) over all folds. This gives you a better estimation of your testing error since you train multiple models with the same parameters on the data and average their performance which reduces the bias of your estimation. You can perform k-fold cv for the same model with different sets of parameters to perform grid search and see which set of parameters has the best estimated testing error.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
